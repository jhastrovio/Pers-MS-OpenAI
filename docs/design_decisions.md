# Pers MS OpenAI â€“ Architectural Decision Record (ADR Log)

Version: 1.5 â€“ 13 May 2025

---

## ğŸ¯ Purpose

Maintain a concise, versionâ€‘controlled trail of **architectural decisions only**. Delivery status & future work sit in `ROADMAP.md`.

---

## ğŸ“‘ Index

| ID      | Title                                                        | Status    | Date        |
| ------- | ------------------------------------------------------------ | --------- | ----------- |
| ADRâ€‘001 | FastAPI as backend orchestrator                              | Accepted  | 10â€¯Mayâ€¯2025 |
| ADRâ€‘002 | OpenAI SDKs as primary LLM & Agent endpoints                 | Accepted  | 10â€¯Mayâ€¯2025 |
| ADRâ€‘003 | Email & attachment ingestion via JSONL â†’ Vector Store        | Accepted  | 10â€¯Mayâ€¯2025 |
| ADRâ€‘004 | Structured JSON response schema for answers                  | Accepted  | 10â€¯Mayâ€¯2025 |
| ADRâ€‘005 | OpenAI Vector Store for Phaseâ€¯1â€“2 storage                    | Accepted  | 10â€¯Mayâ€¯2025 |
| ADRâ€‘006 | Custom GPT Action â†’ Tiny Proxy â†’ Responses API & File Search | Accepted  | 13â€¯Mayâ€¯2025 |
| ADRâ€‘007 | Microsoft Authentication Library (MSAL) for OAuth2           | Proposed  | â€“           |
| ADRâ€‘008 | Azure Application Insights for observability                 | Proposed  | â€“           |
| ADRâ€‘009 | Catalogue of rejected alternatives                           | Catalogue | 13â€¯Mayâ€¯2025 |

---

### ADRâ€‘001 FastAPI as backend orchestrator

**Status:** Accepted â€“ 10â€¯Mayâ€¯2025
Need async, highâ€‘performance Python API; chose FastAPI for `/rag`, health, and future endpoints.

---

### ADRâ€‘002 OpenAI SDKs as primary LLM & Agent endpoints

**Status:** Accepted â€“ 10â€¯Mayâ€¯2025
Use `openai` and `openaiâ€‘agents` exclusively for chat/RAG; no raw REST calls.

---

### ADRâ€‘003 Email & attachment ingestion via JSONL â†’ Vector Store

**Status:** Accepted â€“ 10â€¯Mayâ€¯2025
Serialise emails to JSONL; ingest attachments separately with metadata links.

---

### ADRâ€‘004 Structured JSON response schema for answers

**Status:** Accepted â€“ 10â€¯Mayâ€¯2025
All answers return `{ answer, citations[], confidence }` before rendering.

---

### ADRâ€‘005 OpenAI Vector Store for Phaseâ€¯1â€“2 storage

**Status:** Accepted â€“ 10â€¯Mayâ€¯2025
Up to 10â€¯k docs; supports native metadata filters. Migrate when cap or cost exceeded (tracked in `ROADMAP.md`).

---

### ADRâ€‘006 Custom GPT Action â†’ Tiny Proxy â†’ Responses API & File Search

**Status:** Accepted â€“ 13â€¯Mayâ€¯2025

#### Context

We want users to stay inside the familiar ChatGPT UI **and** tap the full GA Retrieval featureâ€‘set (metadata filters, streaming). ChatGPT *Actions* allow a Custom GPT to invoke an external HTTPS endpointâ€”our tiny proxyâ€”so we can forward the request to `responses.create()` which supports metadata filters.

#### Decision

Build a private **Custom GPT** with one Action `/rag` that calls a **tiny proxy** (FastAPI in Azure Container App or Cloudflare Worker). The proxy translates the payload into a single SDK call:

```python
client.responses.create(
    model="gpt-4o",
    input=req.json["prompt"],
    tools=[{
        "type": "file_search",
        "vector_store_ids": [VS_ID],
        "file_search": {"filters": req.json.get("filters", {})}
    }]
)
```

Proxy returns `{ "answer": resp.output_text }`.

#### Endâ€‘toâ€‘End Picture (Who / What / When)

| Step | Actor / Layer       | What happens                                                |
| ---- | ------------------- | ----------------------------------------------------------- |
| 1    | **User in ChatGPT** | Types a question.                                           |
| 2    | **Custom GPT**      | Detects question needs Action, calls `/rag`.                |
| 3    | **Tiny Proxy**      | Builds `responses.create()` call (adds metadata `filters`). |
| 4    | **Responses API**   | Searches Vector Store, streams answer back.                 |
| 5    | **Tiny Proxy**      | Extracts `output_text`, returns JSON.                       |
| 6    | **Custom GPT**      | Renders answer to user.                                     |

Latencies: ChatGPTâ†’Proxy (â‰ˆ200â€¯ms regional), Proxyâ†’OpenAI (â‰ˆ100â€¯ms). Target P95 â‰¤â€¯4â€¯s remains.

#### Consequences

* âœ… **Zero frontâ€‘end code** â€“ users stay in ChatGPT.
* âœ… **Full GA features** (metadata, streaming, JSON mode) because proxy uses latest SDK.
* âœ… **Extensible** â€“ future rerankers or hybrid search can be added inside proxy.
* âŒ **Extra hop** adds small latencyâ€”mitigated by regional coâ€‘location.
* âŒ **Secrets** live in proxy; Key Vault integration scheduled (ADRâ€‘007).

---

### ADRâ€‘007 Microsoft Authentication Library (MSAL) for OAuth2

**Status:** Proposed
Plan to adopt MSAL clientâ€‘credential flow for Graph & Key Vault access.

---

### ADRâ€‘008 Azure Application Insights for observability

**Status:** Proposed
Add distributed tracing & metrics; alert on latency & errors.

---

### ADRâ€‘009 Rejected alternatives (catalogue)

| Option                                      | Reason                                           |
| ------------------------------------------- | ------------------------------------------------ |
| Direct UI (Teams bot / web) + Responses API | Adds frontâ€‘end build; user loses ChatGPT context |
| LangChain orchestrator                      | Too heavy for scoped use                         |
| LlamaIndex pipeline                         | Missing advanced metadata support                |
| Selfâ€‘hosted vector DB (Pinecone, Qdrant)    | Adds ops overhead at MVP                         |

---

## ğŸ—’ï¸ Changelog

* **v1.5 â€“ 13â€¯Mayâ€¯2025** â€“ Reâ€‘aligned with Optionâ€¯A: ADRâ€‘006 accepted; removed ADRâ€‘010; added endâ€‘toâ€‘end flow & consequences.
* **v1.4 â€“ 13â€¯Mayâ€¯2025** â€“ (superseded) temporary pivot to direct Responses API.
